{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6abf8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dea394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('A:\\python\\MATLAB\\lena.jpg')\n",
    "image.shape\n",
    "'''\n",
    "cv2.imshow('lena',image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "#create an image \n",
    "'''\n",
    "cv2.imwrite('lina.jpg',image)\n",
    "cv2.imshow('lena1',image)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "#Grey lena image\n",
    "gray_lena=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('gray_lena',gray_lena)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23b3ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(B.shape)\\ncv2.imshow('Red image',B)\\ncv2.imshow('Green image',G)\\ncv2.imshow('Blue image',R)\\ncv2.waitKey()\\ncv2.destroyAllWindows()\\n\\n#merge RGB values\\nmerge=cv2.merge([B,G,R+100])\\ncv2.imshow('merged',merge)\\ncv2.waitKey(0)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split RGB values\n",
    "B,G,R=cv2.split(image)\n",
    "'''\n",
    "print(B.shape)\n",
    "cv2.imshow('Red image',B)\n",
    "cv2.imshow('Green image',G)\n",
    "cv2.imshow('Blue image',R)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#merge RGB values\n",
    "merge=cv2.merge([B,G,R+100])\n",
    "cv2.imshow('merged',merge)\n",
    "cv2.waitKey(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6d743e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ngamma_two_point_two = np.array(255*(R/255)**2.2,dtype='uint8')\\ngamma_point_four = np.array(255*(B/255)**0.4,dtype='uint8')\\n \\n# Horizontally concatenate the 2 images\\nimg3 = cv2.hconcat([gamma_two_point_two,gamma_point_four])\\n \\n# Display the concatenated image\\ncv2.imshow('a2',img3)\\ncv2.waitKey(0)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subplots\n",
    "'''\n",
    "gamma_two_point_two = np.array(255*(R/255)**2.2,dtype='uint8')\n",
    "gamma_point_four = np.array(255*(B/255)**0.4,dtype='uint8')\n",
    " \n",
    "# Horizontally concatenate the 2 images\n",
    "img3 = cv2.hconcat([gamma_two_point_two,gamma_point_four])\n",
    " \n",
    "# Display the concatenated image\n",
    "cv2.imshow('a2',img3)\n",
    "cv2.waitKey(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d732a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video making\n",
    "'''\n",
    "import cv2\n",
    "image=cv2.VideoCapture(0)\n",
    "fourcc_code=cv2.VideoWriter_fourcc(*'XVID')\n",
    "video=cv2.VideoWriter('my_video1.avi',fourcc_code,30,(640,480))\n",
    "c=0\n",
    "while(True):\n",
    "    c=c+1\n",
    "    check,frame=image.read()\n",
    "    video.write(frame)\n",
    "    cv2.imshow('My_image1',frame)\n",
    "    if cv2.waitKey()==ord('q'):\n",
    "        break\n",
    "    cv2.imwrite('My_image'+str(c)+'.jpg',frame) \n",
    "image.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capturing images from phone or raspberry pi or other mobile devices\n",
    "#same code just downlaod IP WEBCAM app from play store\n",
    "'''\n",
    "import cv2\n",
    "image=cv2.VideoCapture('http://192.168.0.102:8080/video')\n",
    "fourcc_code=cv2.VideoWriter_fourcc(*'XVID')\n",
    "video=cv2.VideoWriter('my_video1.avi',fourcc_code,30,(1920,1080))\n",
    "c=0\n",
    "while(True):\n",
    "    c=c+1\n",
    "    check,frame=image.read()\n",
    "    video.write(frame)\n",
    "    cv2.imshow('My_image1',frame)\n",
    "    if cv2.waitKey()==ord('q'):\n",
    "        break\n",
    "    cv2.imwrite('My_image'+str(c)+'.jpg',frame) \n",
    "image.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3240c115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#webcam Image capture\\nimage=cv2.VideoCapture(0)\\nc=0\\nwhile(True):\\n   c=c+1\\n   check,frame=image.read()\\n   cv2.imshow('my image',frame)\\n   if cv2.waitKey()==ord('q'):#if cv2.waitKey(1) then infinite loop of values\\n     break        \\n   cv2.imwrite('I1.jpg',frame)\\nimage.release()\\ncv2.destroyAllWindows()\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#webcam Image capture\n",
    "image=cv2.VideoCapture(0)\n",
    "c=0\n",
    "while(True):\n",
    "   c=c+1\n",
    "   check,frame=image.read()\n",
    "   cv2.imshow('my image',frame)\n",
    "   if cv2.waitKey()==ord('q'):#if cv2.waitKey(1) then infinite loop of values\n",
    "     break        \n",
    "   cv2.imwrite('I1.jpg',frame)\n",
    "image.release()\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "390a84ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Geometry on images\n",
    "'''\n",
    "import numpy as np\n",
    "import cv2\n",
    "i0=np.zeros((512,512,3),np.uint8) #data type is uint8  used for having no sign and thus always poositive hence easy to manipulate\n",
    "print(type(i1))\n",
    "\n",
    "i1=cv2.imread('A:\\python\\MATLAB\\lena.jpg')\n",
    "#i2=cv2.cvtColor(i1,cv2.COLOR_BGR2GRAY)\n",
    "#cv2.imshow('black',i0)\n",
    "#cv2.line(i1,(10,10),(255,255),(255,0,0),5)#thickness is 5\n",
    "\n",
    "#Geometric shapes\n",
    "\n",
    "#Makeing a line\n",
    "#1.line\n",
    "#cv2.line(i1,(10,10),(255,255),(255,0,0),5)\n",
    "#2.arrowed line\n",
    "cv2.arrowedLine(i1,(0,0),(213,215),(255,0,0),5)\n",
    "#3.Rectangle\n",
    "cv2.rectangle(i1,(213,215),(361, 390),(0,255,0),2)#points are end points of diagonals\n",
    "#4. Circle\n",
    "#get coordinates of pixels from matlab  lena=imread('lena.jpg'); imshow(lena) imfinfo('lena.jpg') impixelinfo\n",
    "#cv2.circle(i1,(311,301),75,(0,0,255),5)#-1 for filling the circle or rectangle\n",
    "\n",
    "#5.Text\n",
    "cv2.putText(i1,\"lena\",(298,384),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0),3)\n",
    "\n",
    "cv2.imshow('lena',i1)\n",
    "#cv2.imshow('black',i0)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2ffcbfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "# MOUSE click action\n",
    "def mouse_event(event,x,y,flag,params):\n",
    "    #event is variable which gets a value depending on mouse click\n",
    "    if (event==cv2.EVENT_LBUTTONDOWN):\n",
    "        str1=str(x)+\",\"+str(y)\n",
    "        points.append((x,y))\n",
    "        cv2.putText(lena,str1,(x,y),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0),3)\n",
    "        #if len(points)==2:\n",
    "           # cv2.rectangle(lena,points[0],points[1],(0,255,0),10)\n",
    "      \n",
    "        \n",
    "        \n",
    "    cv2.imshow('lena',lena)  \n",
    "\n",
    "\n",
    "\n",
    "lena=cv2.imread('A:\\python\\MATLAB\\lena.jpg')\n",
    "points=[]\n",
    "cv2.imshow('lena',lena)\n",
    "cv2.setMouseCallback('lena',mouse_event)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc5613f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Extract RGB Values from the image\n",
    "import cv2\n",
    "import numpy as np\n",
    "def mouse_event(event,x,y,flag,params):\n",
    "     #points.append((x,y))\n",
    "    if (event==cv2.EVENT_RBUTTONDOWN):\n",
    "        blue=image[y,x,0]\n",
    "        green=image[y,x,1]\n",
    "        red=image[y,x,2]\n",
    "        #putting text of pixel RGB values     \n",
    "        str1=str(blue)+\",\"+str(green)+\",\"+str(red)   \n",
    "        cv2.putText(image,str1,(x,y),cv2.FONT_ITALIC,1,(0,0,0),1)  \n",
    "        cv2.imshow('Rgb values',image)\n",
    "        \n",
    "        image1=np.zeros((512,512,3),np.uint8)    \n",
    "        image1[:]=[blue,green,red]    \n",
    "        cv2.imshow('RGB crop image',image1)       \n",
    "        \n",
    "\n",
    "image=cv2.imread('A:\\python\\MATLAB\\lena.jpg')\n",
    "cv2.imshow('image',image)\n",
    "points=[]\n",
    "cv2.setMouseCallback('image',mouse_event)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "'''\n",
    "#Draw continuous poly line\n",
    "def mouse_event(event,x,y,flag,params):\n",
    "    if (event==cv2.EVENT_MOUSEMOVE):\n",
    "        points.append((x,y))\n",
    "        if (len(points)>=2):\n",
    "            cv2.line(image2,points[-2],points[-1],(204,102,0),3)\n",
    "\n",
    "    cv2.imshow('image2',image2)        \n",
    "image2=cv2.imread('A:\\python\\MATLAB\\lena.jpg') \n",
    "points=[]\n",
    "cv2.imshow('image2',image2)\n",
    "cv2.setMouseCallback('image2',mouse_event)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "'''\n",
    "#croping certain part of image\n",
    "def mouse_event(event,x,y,flag,params):\n",
    "    if (event==cv2.EVENT_LBUTTONDOWN):\n",
    "        points.append((x,y))\n",
    "        if len(points)==2:\n",
    "         cv2.rectangle(image2,points[0],points[1],(255,255,153),3)  \n",
    "         crop_image=image2[points[-2][1]:points[-1][1],points[-2][0]:points[-1][0]]\n",
    "         cv2.imshow('image2',image2)\n",
    "         cv2.imshow('image2',crop_image)\n",
    "image2=cv2.imread('A:\\python\\MATLAB\\lena.jpg') \n",
    "cv2.imshow('image2',image2)\n",
    "points=[]\n",
    "cv2.setMouseCallback('image2',mouse_event)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "#for line outside the if statement but for all others they are within the if statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c365134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arithmetic operations on images\n",
    "'''\n",
    "image1=cv2.imread('A:\\python\\MATLAB\\lena.jpg')\n",
    "image2=cv2.imread(\"A:\\python\\MATLAB\\kane.jpg\")\n",
    "image3=cv2.imread('A:\\python\\MATLAB\\opencv_logo.png')\n",
    "ameya_image=cv2.imread('A:\\python\\MATLAB\\compressed_ameya_image.jpg')\n",
    "'''\n",
    "'''\n",
    "#image3=image3+200\n",
    "image0=np.ones(image2.shape,np.uint8)\n",
    "image0=cv2.add(image0,200)\n",
    "'''\n",
    "'''\n",
    "#increasing brightness of image2 kane\n",
    "#make an image of ones then add that image to the existing image you want to increase brightness of\n",
    "image0=np.zeros(image2.shape,np.uint8)\n",
    "image0=image0+100\n",
    "image4=cv2.add(image2,image0)\n",
    "'''\n",
    "'''\n",
    "#adding images together\n",
    "#the images need to be in same size\n",
    "image2_new=cv2.resize(image2,(512,512))\n",
    "print(image2_new.shape)\n",
    "print(image3.shape)\n",
    "ameya_image_new=cv2.resize(ameya_image,(512,512))\n",
    "image4_new=cv2.addWeighted(image2_new,0.5,ameya_image_new,0.7,0)#gamma keep as 0\n",
    "\n",
    "cv2.imshow('frame0',image4_new)\n",
    "#cv2.imshow('frame1',image1)\n",
    "#cv2.imshow('frame2',image2)\n",
    "#cv2.imshow('frame3',image3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "'''\n",
    "\n",
    "#Bitwise operations\n",
    "#Generally used for applying masks\n",
    "import numpy as np \n",
    "import cv2\n",
    "'''\n",
    "image1=cv2.imread('A:\\python\\MATLAB\\lena.jpg')\n",
    "image_mask1=np.zeros(image1.shape,np.uint8)\n",
    "image_mask2=np.zeros(image1.shape,np.uint8)\n",
    "#defining the circle and rectangle mask dimensions\n",
    "cv2.rectangle(image_mask1,(50,50),(300,300),(255,255,255),-1)\n",
    "cv2.circle(image_mask2,(275,275),50,(255,255,255),-1)\n",
    "\n",
    "image4=cv2.bitwise_and(image1,image_mask2)\n",
    "image3=cv2.bitwise_and(image1,image_mask1)\n",
    "cv2.imshow('frame3',image3)\n",
    "cv2.imshow('frame4',image4)\n",
    "image5=cv2.bitwise_not(image1)\n",
    "cv2.imshow('frame 5',image5)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25d1b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translation and Rotation\n",
    "import cv2\n",
    "import numpy as np\n",
    "ameya=cv2.imread('A:\\python\\MATLAB\\compressed_ameya_image.jpg')\n",
    "'''\n",
    "# For Translation\n",
    "row,col,ch,=ameya.shape\n",
    "x=50\n",
    "y=80\n",
    "T=np.float64([[1,0,x],[0,1,y]])\n",
    "ameya2=cv2.warpAffine(ameya,T,(col,row))\n",
    "cv2.imshow('Image',ameya2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "'''\n",
    "#Animation using translation\n",
    "row,col,ch,=ameya.shape\n",
    "x=0\n",
    "y=0\n",
    "while(True):\n",
    "    T=np.float64([[1,0,x],[0,1,y]])\n",
    "    ameya2=cv2.warpAffine(ameya,T,(col,row))\n",
    "    cv2.imshow('Image',ameya2)\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==ord('q'):\n",
    "        break\n",
    "    x=x+1\n",
    "    y=y+1\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "#Rotation\n",
    "#For rotation no T matrix we use inbuilt functions\n",
    "'''\n",
    "row,col,ch,=ameya.shape\n",
    "x=0\n",
    "y=0\n",
    "angle=0\n",
    "while(True):\n",
    "    if angle==360:\n",
    "        angle=0\n",
    "    R=cv2.getRotationMatrix2D((row/2,col/2),angle,0.5)#axis center angle and scale  \n",
    "    ameya2=cv2.warpAffine(ameya,R,(col,row))\n",
    "    cv2.imshow('Image',ameya2)\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==ord('q'):\n",
    "        break\n",
    "    angle=angle+5    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4cc4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Scaling \n",
    "#sharpening is increasing at corner\n",
    "import cv2\n",
    "import numpy as np\n",
    "lena=cv2.imread('A:\\python\\MATLAB\\lena.jpg')\n",
    "#method1 Interpolation for zoom use cubic or  lancz054 and for minimize use area\n",
    "#lena_scale=cv2.resize(lena,None,fx=1.5,fy=1.5,interpolation=cv2.INTER_LANCZOS4)\n",
    "#lena_scale=cv2.resize(lena,None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#method 2 pyramid gives less control\n",
    "#lena_scale=cv2.pyrUp(lena)\n",
    "#lena_scale=cv2.pyrDown(lena)\n",
    "\n",
    "cv2.imshow('lena_scale',lena_scale)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6169ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bluring and smoothening of images remove noise and improve the pixels \n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "lena=cv2.imread('A:\\python\\MATLAB\\lena.jpg')\n",
    "#smaller the kernel size less the blurring effect\n",
    "#low pass filter for blurring and smoothing \n",
    "kernel_5x5=np.ones((5,5),np.uint8)/25 #kernel 5x5  so divide by 25\n",
    "kernel_9x9=np.ones((5,5),np.uint8)/81\n",
    "#method 1 using a kernel and filter2d function own kernel as filter\n",
    "# ddepth means desired depth of the destination image\n",
    "#when ddepth=-1, the output image will have the same depth as the source.\n",
    "#i1=cv2.filter2D(lena,-1,kernel_5x5)\n",
    "#method2 using the built in filter\n",
    "#i1=cv2.GaussianBlur(lena,(5,5),0)\n",
    "#i1=cv2.blur(lena,(5,5))\n",
    "#i1=cv2.medianBlur(lena,5)\n",
    "#i1=cv2.bilateralFilter(lena,45,75,75)#gives good values for edges 40 is size and 75 is sigma color ie 175 and 100 are considered same and 75 as color space ie differnce of 75 is needed for colors to be different\n",
    "#high pass filter for sharpening\n",
    "kernel=np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "i1=cv2.filter2D(lena,-1,kernel)\n",
    "cv2.imshow('blurring',i1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2684a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Threshold simple and adaptive\n",
    "import cv2\n",
    "import numpy as np\n",
    "lena=cv2.imread('A:\\python\\MATLAB\\lena.jpg')\n",
    "#can be used for both gray and rgb images but with gray we get better results\n",
    "#use for b/w images for better understanding and used to find intricate parts  in an image eg satellite ones\n",
    "lena_gray=cv2.cvtColor(lena,cv2.COLOR_BGR2GRAY)\n",
    "#Simple thresholding\n",
    "#ret,lena_gray_out=cv2.threshold(lena_gray,140,205,cv2.THRESH_BINARY)# values less than 140 are 0 and others are 205\n",
    "#ret,lena_gray_out=cv2.threshold(lena_gray,140,205,cv2.THRESH_BINARY_INV)# not of thresh binary\n",
    "#ret,lena_gray_out=cv2.threshold(lena_gray,140,205,cv2.THRESH_TRUNC)#values less than 140 are kept as it is and ceil is applied at 140 value as greater values are set to 140 only\n",
    "#ret,lena_gray_out=cv2.threshold(lena_gray,140,205,cv2.THRESH_TOZERO)#values less than 140 are kept as 0 and above are same \n",
    "\n",
    "#adaptive thresholding used generally for sudoko and text type of problems\n",
    "#lena_gray_out=cv2.adaptiveThreshold(lena_gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,5,3)# More the constant better the clearity and block size as odd and greater than 1\n",
    "#lena_gray_out=cv2.adaptiveThreshold(lena_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,5,3)\n",
    "\n",
    "#Erosion and dilation used for thinning and thickening a=the edges or boundaries of the image\n",
    "kernel1=np.ones((5,5),np.uint8)\n",
    "#lena_gray_out=cv2.erode(lena_gray_out,kernel1,iterations=1)#thins the edges\n",
    "#lena_gray_out=cv2.dilate(lena_gray_out,kernel1,iterations=1)#thickens the edges\n",
    "#lena_gray_out=cv2.morphologyEx(lena_gray_out,cv2.MORPH_CLOSE,kernel1)#close does dilate first then erode and for open its viceversa\n",
    "cv2.imshow('thresholding',lena_gray_out)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dce3084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edege Detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "lena=cv2.imread('A:\\python\\MATLAB\\lena.jpg')\n",
    "ameya=cv2.imread('A:\\python\\MATLAB\\compressed_ameya_image.jpg')\n",
    "kane=cv2.imread(\"A:\\python\\MATLAB\\kane.jpg\")\n",
    "'''\n",
    "edge=cv2.Canny(ameya,30,150)\n",
    "edge_enlarged=cv2.pyrUp(edge)\n",
    "cv2.imshow('edge',edge_enlarged)\n",
    "'''\n",
    "#Scaling program\n",
    "#method 1 gaussian\n",
    "# In gaussian method the image size is reduced blurring is seen\n",
    "def gaussian(image):\n",
    "    gp=[image]\n",
    "    for i in range(3):#iterates till 0 to 5 of image dow sizing   \n",
    "      image=cv2.pyrDown(image)\n",
    "      gp.append(image)\n",
    "      cv2.imshow(str(image.shape),gp[i])\n",
    "  \n",
    "def laplacian(image):\n",
    "    gp=[image]\n",
    "    for i in range(3):\n",
    "      image=cv2.pyrDown(image)  \n",
    "      gp.append(image)\n",
    "    lp=[gp[3]] \n",
    "    #Laplacian we take difference between between last and the one previous \n",
    "    for i in range(3,0,-1) :\n",
    "      gauss_expand=cv2.pyrUp(gp[i])\n",
    "      lap=cv2.subtract(gp[i-1],gauss_expand)\n",
    "      lp.append(lap)\n",
    "      cv2.imshow(str(i),lap)\n",
    "      cv2.waitKey()\n",
    "      cv2.destroyAllWindows()\n",
    "    return lap    \n",
    "        \n",
    "        \n",
    "'''\n",
    "      cv2.waitKey()\n",
    "      cv2.destroyAllWindows()\n",
    "'''   \n",
    "      \n",
    "''' \n",
    "\n",
    "def laplacian(image):\n",
    "    gp=[image]\n",
    "    for i in range(3):\n",
    "        image=cv2.pyrDown(image)\n",
    "        gp.append(image)\n",
    "    for i in range(3,0-1):\n",
    "        gauss_expand=cv2.pyrUp(i)\n",
    "        lap=cv2.subtract(gp[i-1],gauss_expand)\n",
    "        lp.append(lap)\n",
    "        cv2.imshow(str(i),lap)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "    return lap    \n",
    "        \n",
    "'''         \n",
    "#cv2.imshow('edge',edge)\n",
    "#gaussian(lena)\n",
    "#(lena)#gives output like edge detection\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99dbb5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To call a function from outside we need to write wait key and destroy all windows\n",
    "laplacian(lena)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b334b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blending images together\n",
    "import cv2\n",
    "import numpy as np\n",
    "mango=cv2.imread('A:\\\\python\\\\MATLAB\\\\mango.jpg')\n",
    "orange=cv2.imread('A:\\\\python\\\\MATLAB\\\\org.jpg')\n",
    "#built in function to merge 2 images take their parts and then merge\n",
    "'''\n",
    "orange=cv2.imread('A:\\python\\MATLAB\\orange.jpg')\n",
    "print(orange.shape)\n",
    "apple=cv2.imread('A:\\python\\MATLAB\\apple.jpg')\n",
    "#apple=cv2.resize(apple,(512,512))\n",
    "#apple_orange_combined=np.hstack((apple[:,:256],orange[:,256:]))#this is equivalent to size of image\n",
    "apple_orange_combined=np.hstack((apple[:,:112],orange[:,112:]))\n",
    "#cv2.imshow('apple',apple)\n",
    "#cv2.imshow('orange',orange)\n",
    "cv2.imshow('apple_orange_merged',apple_orange_combined)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "\n",
    "#combined_image\n",
    "#using blend form of image reduce the image to lowest form then blend\n",
    "#blending images together\n",
    "import cv2\n",
    "import numpy as np\n",
    "apple=cv2.imread('A:\\\\python\\\\MATLAB\\\\apple.jpg')\n",
    "orange=cv2.imread('A:\\\\python\\\\MATLAB\\\\org.jpg')\n",
    "#built in function to merge 2 images take their parts and then merge\n",
    "'''\n",
    "orange=cv2.imread('A:\\python\\MATLAB\\orange.jpg')\n",
    "print(orange.shape)\n",
    "apple=cv2.imread('A:\\python\\MATLAB\\apple.jpg')\n",
    "#apple=cv2.resize(apple,(512,512))\n",
    "#apple_orange_combined=np.hstack((apple[:,:256],orange[:,256:]))#this is equivalent to size of image\n",
    "apple_orange_combined=np.hstack((apple[:,:112],orange[:,112:]))\n",
    "#cv2.imshow('apple',apple)\n",
    "#cv2.imshow('orange',orange)\n",
    "cv2.imshow('apple_orange_merged',apple_orange_combined)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "\n",
    "#combined_image\n",
    "#using blend form of image reduce the image to lowest form then blend\n",
    "#laplacian(orange)\n",
    "def laplacian(image):\n",
    "    gp=[image]\n",
    "    for i in range(3):\n",
    "      image=cv2.pyrDown(image)\n",
    "      gp.append(image)\n",
    "    lp=[gp[3]]\n",
    "    #Laplacian we take difference between between last and the one previous\n",
    "    for i in range(3,0,-1) :\n",
    "      gauss_expand=cv2.pyrUp(gp[i])\n",
    "      lap=cv2.subtract(gp[i-1],gauss_expand)\n",
    "      lp.append(lap)\n",
    "      #cv2.imshow(str(i),lap)\n",
    "      cv2.waitKey()\n",
    "      cv2.destroyAllWindows()\n",
    "    return lap\n",
    "\n",
    "\n",
    "#decomposing the image into smallest form so it is easy to the built them up by laplacian methods as small form easy to blend\n",
    "lp_apple=[]\n",
    "lp_orange=[]\n",
    "lp_apple=laplacian(apple)\n",
    "lp_orange=laplacian(orange)\n",
    "\n",
    "stack=[]\n",
    "#joining 2 objects together\n",
    "orange=cv2.resize(orange,(512,512))\n",
    "for apple_lap,orange_lap in zip(lp_apple,lp_orange):\n",
    "    col,rows,ch=apple.shape\n",
    "    lap=np.hstack((apple_lap[:,:int(col/2)],orange_lap[:,int(col/2):]))\n",
    "    stack.append(lap)\n",
    "\n",
    "recons=stack[0]\n",
    "for i in range(1,3):\n",
    "    recons=cv2.pyrUp(recons)\n",
    "    recons=cv2.add(stack[i],recons)\n",
    "\n",
    "\n",
    "cv2.imshow('images blended',recons)\n",
    "#lp_apple=laplacian(mango)\n",
    "#cv2.imshow('mango',mango)\n",
    "#cv2.imshow('orange',orange)\n",
    "cv2.imshow()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "339eb31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "print(apple.shape)\n",
    "print(orange.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3472254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blending images together\n",
    "import cv2\n",
    "import numpy as np\n",
    "apple=cv2.imread('A:\\\\python\\\\MATLAB\\\\apple.jpg')\n",
    "orange=cv2.imread('A:\\\\python\\\\MATLAB\\\\org.jpg')\n",
    "apple=cv2.resize(apple,(512,512))\n",
    "orange=cv2.resize(orange,(512,512))\n",
    "#built in function to merge 2 images take their parts and then merge\n",
    "'''\n",
    "orange=cv2.imread('A:\\python\\MATLAB\\orange.jpg')\n",
    "print(orange.shape)\n",
    "apple=cv2.imread('A:\\python\\MATLAB\\apple.jpg')\n",
    "apple=cv2.resize(apple,(512,512))\n",
    "apple=cv2.resize(apple,(512,512))\n",
    "#apple_orange_combined=np.hstack((apple[:,:256],orange[:,256:]))#this is equivalent to size of image\n",
    "apple_orange_combined=np.hstack((apple[:,:112],orange[:,112:]))\n",
    "#cv2.imshow('apple',apple)\n",
    "#cv2.imshow('orange',orange)\n",
    "cv2.imshow('apple_orange_merged',apple_orange_combined)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "'''\n",
    "#combined_image\n",
    "#using blend form of image reduce the image to lowest form then blend\n",
    "#laplacian(orange)\n",
    "def laplacian(image):\n",
    "    gp=[image]\n",
    "    for i in range(3):\n",
    "      image=cv2.pyrDown(image)\n",
    "      gp.append(image)\n",
    "    lp=[gp[3]]\n",
    "    #Laplacian we take difference between between last and the one previous\n",
    "    for i in range(3,0,-1) :\n",
    "      gauss_expand=cv2.pyrUp(gp[i])\n",
    "      lap=cv2.subtract(gp[i-1],gauss_expand)\n",
    "      lp.append(lap)\n",
    "      #cv2.imshow(str(i),lap)\n",
    "      cv2.waitKey()\n",
    "      cv2.destroyAllWindows()\n",
    "    return lp\n",
    "\n",
    "\n",
    "#decomposing the image into smallest form so it is easy to the built them up by laplacian methods as small form easy to blend\n",
    "lp_apple=[]\n",
    "lp_orange=[]\n",
    "lp_apple=laplacian(apple)\n",
    "lp_orange=laplacian(orange)\n",
    "\n",
    "stack=[]\n",
    "#joining 2 objects together\n",
    "#orange=cv2.resize(orange,(512,512))\n",
    "for apple_lap,orange_lap in zip(lp_apple,lp_orange):\n",
    "    col,rows,ch=apple_lap.shape\n",
    "    lap=np.hstack((apple_lap[:,:int(col/2)],orange_lap[:,int(col/2):]))\n",
    "    stack.append(lap)\n",
    "\n",
    "recons=stack[0]\n",
    "for i in range(1,3):\n",
    "    recons=cv2.pyrUp(recons)\n",
    "    recons=cv2.add(stack[i],recons)\n",
    "\n",
    "\n",
    "cv2.imshow('images blended',recons)\n",
    "#lp_apple=laplacian(mango)\n",
    "#cv2.imshow('mango',mango)\n",
    "#cv2.imshow('orange',orange)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "af17ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contours\n",
    "'''\n",
    "original_image=cv2.imread('A:\\python\\MATLAB\\opencv_logo.png')\n",
    "image=cv2.imread('A:\\python\\MATLAB\\opencv_logo.png')\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "ret,image=cv2.threshold(image,170,255,0)\n",
    "#cv2.imshow('contours',image)\n",
    "image=cv2.Canny(image,30,70)\n",
    "\n",
    "contours,hierarchy=cv2.findContours(image,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)# simplex for only selected points not all\n",
    "#tree for both inner and outer contours\n",
    "#external method takes only the outer points and contours\n",
    "cv2.drawContours(original_image,contours,-1,(0,0,0),5)#color of contours  5 for thickness -1 for all indexes\n",
    "cv2.imshow('contours',original_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "# website for colors mask range https://stackoverflow.com/questions/36817133/identifying-the-range-of-a-color-in-hsv-using-opencv/51686953\n",
    "#for red 2 maks for else use 1 mask is enough to segment out that color\n",
    "original_image=cv2.imread('A:\\python\\MATLAB\\opencv_logo.png')\n",
    "image=cv2.imread('A:\\python\\MATLAB\\opencv_logo.png')\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "#Matching components from an image and color detection using masks\n",
    "#finding only red parts in the logo\n",
    "ur1=np.array((180, 255, 255))\n",
    "lr1=np.array((159, 50, 70))\n",
    "ur2=np.array((9, 255, 255))\n",
    "lr2=np.array((0, 50, 70))\n",
    "\n",
    "mask1=cv2.inRange(image,lr1,ur1)\n",
    "mask2=cv2.inRange(image,lr2,ur2)\n",
    "mask=mask1+mask2\n",
    "contours,hierarchy=cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(original_image,contours,-1,(200,100,0),5)\n",
    "\n",
    "cv2.imshow('contours',original_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "631c04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matching contours and object detection in an image\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
